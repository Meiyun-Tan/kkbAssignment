# Q1:什么是反向传播中的链式法则?

根据微积分的知识，利用$f(g(x))' = f'(g(x)) * g'(x)$这个恒等式对函数链进行求导，称为链式法则。将链式法则应用于神经网络梯度值的计算，得到的算法称作反向传播算法(Backpropagation，简称 BP)。

反向传播从最终损失值开始，从最顶层反向作用至最底层，利用链式法则计算每个参数对损失值的贡献大小；基于梯度下降策略，以loss函数的负梯度方向对参数(权重、偏置)进行调整，从而达到loss最小的目标。

# Q2: 请列举几种常见的激活函数，激活函数有什么作用?

+ 常见激活函数：

  + Sigmoid 公式:$sigmoid(x) = \frac{1}{1+e^{-x}}$。将输入压缩到(0,1]的范围，常用来表示概率分布或信号强度。缺点是容易出现梯度消失或爆炸。

  + Tanh 公式:$tanh(x) = \frac{e^{x} - e^{-x}}{e^{x}+e^{-x}} = 2sigmoid(2x) - 1$。向量元素值的范围被映射到(-1,1)之间。

  + ReLU 公式:$ReLU(x) = max(0, x)$。对小于 0 的值全部抑制为 0；对于正数则直接输出。由于非负区间的梯度为常数，因此不存在梯度消失问题，使得模型的收敛速度维持在一个稳定状态。

    出。

  + Softmax公式:$softmax(x) = \frac{e^{z_i}}{\sum _{k=1}^{K} e^{z_k}}$。Softmax 函数不仅可以将输出值映射到[0,1]区间，还满足所有的输出值之和为 1 的特性。

+ 激活函数的作用：

  + 激活函数是非线性的，而现实中的问题，大部分是非线性问题，激活函数的出现使得模型拟合非线性问题成为可能。

# Q3: 利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？

1. **没有对数据进行归一化**；
   + 原因：不同的评价指标往往有不同量纲和量纲单位，这种情况会影响数据分析的结果。另外大部分神经网络流程都假设输入输出是在0附近的分布，从权值初始化到激活函数，从训练到训练网络的优化算法。比如：sigmoid、tanh激活函数，在[-1, 1]区间之外会逐渐不敏感，容易出现梯度消失或爆炸。
   + 解决方法：常用方法是对数据集进行z-score标准化或者最大最小归一化。
2. **数据预处理出现问题**；
   + 原因：标签设置有问题，比如label真实为1，但却设置成了0。数据清洗不干净，存在较差的数据干扰；存在缺失值NaN，导致损失函数也为NaN；
   + 解决办法：思考数据的特征，是否有简单的变换、是否可以用相似的数值表示等。
3. **批训练样本太大**；
   + 原因：使用较大的训练样本可能对网络的训练过程中的准确性造成负面影响，因为大样本会破坏梯度下降的随机性。
   + 尽可能向的缩减样本尺寸，利用GPU并行，用更多训练周期训练数据集，以便达到相同的准确率。
4. **缺少正则化**；
   + 原因：当模型出现过拟合的时候，loss将停滞；
   + 解决方法：需要添加dropout层，设置从中到高的训练概率，例如0.75、0.9。如果认为不太可能出现过拟合，则可以设置较高的值。或者设置BN层。
5. **学习率设置太大**；
   + 原因：学习率太大，容易产生震荡，梯度无法到达最低点；
   + 解决方法:降低学习率。
6. **没有正确初始化权重**；
   + 原因：如果没有正确初始化神经网络的权重，神经网络就无法正常工作。比如：初始权重比较大，且激活函数为sigmoid，达到它的不敏感区间，导致梯度为0，参数无法更新；
   + 解决方法："lecun"或"xavier"的权重初始化几乎在所有情况下表现良好。
7. **loss设定的不正确**；
   + 原因：不同的任务，需要使用不同的loss；比如：分类任务需要使用交叉熵损失函数，如果使用了回归任务的MSE等损失函数，模型将无法正常工作。
   + 解决方法：使用正确的损失函数。
8. **Pooling层的步长大于核的尺寸**；
   + 由于一些原因，步长*stride*>核尺寸*kernel_size*的pooling层会出现*NaN*。
   + 解决方法：调整步长和核尺寸。

这个问题也一直是建网络时困扰我的问题。以下是我找到的参考资源链接：

[神经网络不收敛的11个常见问题](https://zhuanlan.zhihu.com/p/36369878)

[深度学习之Loss不下降原因分析篇](https://blog.csdn.net/weixin_42028608/article/details/104611864)

[警惕！损失Loss为Nan或者超级大的原因](https://oldpan.me/archives/careful-train-loss-nan-inf)

[在训练过程中loss出现NaN的原因以及可以采取的方法](https://www.jianshu.com/p/9018d08773e6)








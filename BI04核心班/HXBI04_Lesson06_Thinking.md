# Q1:XGBoost与GBDT的区别是什么？

## A1:

GBDT是一种常用的非线性模型，基于集成学习中的boosting思想，也就是每次迭代都在减少残差的梯度方向新建立一颗决策树，迭代多少次就会生成多少颗决策树。XGBoost是GBDT的工业版本。二者的区别：

+ XGBoost的损失函数，相比GBDT只用到一阶泰勒展开，XGBoost则用到了二阶泰勒展开，因此更加精确。
+ XGBoost将树模型的复杂度加入到正则项中，从而避免过拟合，泛化性能好；
+ XGBoost在寻找最佳分割点时，采用近似贪心算法，用来加速计算；
+ GBDT指的是梯度提升决策树算法。XGBoost不仅支持CART作为基分类器，还支持线性分类器，在使用线性分类器的时候可以使用L1，L2正则化；
+ GBDT没有设计对缺失值的处理，XGBoost能够学习出默认的节点分裂方向来处理缺失值；
+ GBDT每轮使用全部数据，XGBoost支持对数据进行采样。XGBoost将特征列排序后以block的形式存储在内存中，在后面的迭代中重复使用这个结构。在进行节点分裂时，计算每个特征的增益，选择增益最大的特征作为分割节点，各个特征的增益计算可以使用多线程并行。

# Q2:举一个你之前做过的预测例子（用的什么模型，解决什么问题，比如我用LR模型，对员工离职进行了预测，效果如何... 请分享到课程微信群中）

## A2:

+ 项目名称：员工离职预测
+ 问题描述：利用员工在职年限、薪资、工作时长、部门等数据，对员工是否离职进行预测。
+ 使用的模型：KNN, 伯努利贝叶斯 ,逻辑回归，支持向量机，Adaboost，GBDT，随机森林；
+ 最终选择模型：支持向量机SVC
+ 模型效果：kaggle分数：0.82994
+ 首次参加比赛的总结：
  + 首先，通过目标值判断是分类问题还是回归问题；
  + 其次，再通过Evaluation中所标明的衡量指标和sample.csv判断要提交的是什么预测结果，比如员工离职的数据集，Evaluation的评估指标是AUC，且sample.csv是小于1的浮点数，可以判断它要求提供的是预测得到的概率值，这里一定要注意是要提供label值为1对应的概率，提供成0的概率值成绩会相反；
  + 开始对各模型的效果缺少判断，所以广撒网，各模型都预测了下，选了分数最高的一个去提交，得到基准线；
  + 当调参不能提高预测结果的时候，就得考虑特征工程了，尝试过根据特征系数对完全相关列只保留一列；特征工程我还有待学习。

# Q3:请你思考，在你的工作中，需要构建哪些特征（比如用户画像，item特征...），这些特征都包括哪些维度（鼓励分享到微信群中，进行交流）

## A3:

我原来做过中医养生连锁店的会员分析，当时还不会Python。按照现在所学知识的话，我想我会这么处理：

1. 通过会员系统，获取用户的年龄、会员等级、会龄、到店频率、充值金额、充值频率、医师咨询频率，上次到店时间；
2. 通过大众点评，得到下单商品标题、金额、重复购买率；
   1. 通过下单标题提取特征，发现用户偏好，指导上架新套餐；

可以预测用户下次的到店时间，对即将沉默用户进行预警，向顾客推荐与他相似的顾客所喜欢的套餐等等。
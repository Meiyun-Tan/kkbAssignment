{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1-准备数据\" data-toc-modified-id=\"1-准备数据-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1 准备数据</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-加载文本\" data-toc-modified-id=\"1.1-加载文本-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1.1 加载文本</a></span></li><li><span><a href=\"#1.2-将整个文本以句子拆分\" data-toc-modified-id=\"1.2-将整个文本以句子拆分-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>1.2 将整个文本以句子拆分</a></span></li></ul></li><li><span><a href=\"#2-jieba分词\" data-toc-modified-id=\"2-jieba分词-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2 jieba分词</a></span></li><li><span><a href=\"#3-创建MinHashForest及MinHash对象\" data-toc-modified-id=\"3-创建MinHashForest及MinHash对象-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>3 创建MinHashForest及MinHash对象</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-自定义MinHash函数\" data-toc-modified-id=\"3.1-自定义MinHash函数-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>3.1 自定义MinHash函数</a></span></li><li><span><a href=\"#3.2-minhash降维及建forest\" data-toc-modified-id=\"3.2-minhash降维及建forest-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>3.2 minhash降维及建forest</a></span></li><li><span><a href=\"#3.3-索引到目前为止添加的所有key，并使它们可搜索\" data-toc-modified-id=\"3.3-索引到目前为止添加的所有key，并使它们可搜索-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>3.3 索引到目前为止添加的所有key，并使它们可搜索</a></span></li></ul></li><li><span><a href=\"#4-查询top-3近似最近邻居\" data-toc-modified-id=\"4-查询top-3近似最近邻居-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>4 查询top-3近似最近邻居</a></span></li><li><span><a href=\"#5-总结\" data-toc-modified-id=\"5-总结-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>5 总结</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action1要求：    \n",
    "使用MinHashLSHForest对微博新闻句子进行检索 weibo.txt    \n",
    "\n",
    "针对某句话进行Query，查找Top-3相似的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba \n",
    "from datasketch import MinHash, MinHashLSHForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 准备数据\n",
    "## 1.1 加载文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入微博文本\n",
    "with open('weibos.txt', 'r', encoding='utf-8') as f:\n",
    "    contents = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入自定义的停用词\n",
    "with open('stopword.txt', 'r', encoding='utf-8') as f:\n",
    "    # 直接readlines()仍然会有换行符，不如直接整个读取后split\n",
    "    stopwords = f.read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['的', '是', '，', '“', '”', '：']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 将整个文本以句子拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 不可见字符\\u200b的数量\n",
    "contents.count('\\u200b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除不可见字符\\u200b和空格和换行符\n",
    "contents = contents.replace('\\u200b', '').replace(' ', '').replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 按句子拆分\n",
    "sentences = re.split(pattern='[#。！？]', string=contents)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计列表中空字符串数量\n",
    "sentences.count('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 号称去除列表中空字符串最快最简单的方法 == [x for x in your_list if x]，但速度更快\n",
    "# 第一个参数为None，默认会去除序列中所有值为假的元素\n",
    "sentences = list(filter(None, sentences))\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['斯科拉里愿意执教国足', '上一届如果是里皮从头芾到尾，是很大机会入世界杯的，这一届，没几个能用的，除非大力归化，谁来都没用']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 jieba分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/dk/4d4_y1kn1js69jdc1n1xyjtr0000gn/T/jieba.cache\n",
      "Loading model cost 0.713 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for s in sentences:\n",
    "    temp = ' '.join([w for w in jieba.cut(s) if w not in stopwords])\n",
    "    documents.append(temp)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 创建MinHashForest及MinHash对象"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 自定义MinHash函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minhash(doc):\n",
    "    \"\"\"为每个句子生成一个MinHash实例\"\"\"\n",
    "    m  = MinHash(num_perm=128)\n",
    "    for word in doc:\n",
    "        m.update(word.encode('utf-8'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 minhash降维及建forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = MinHashLSHForest(num_perm=128, l=8)\n",
    "minhash_list = []\n",
    "\n",
    "for i,doc in enumerate(documents):\n",
    "    m = get_minhash(doc)\n",
    "    minhash_list.append(m)\n",
    "    # 将minhash对象加入到MinHashLSHForest中\n",
    "    # key和index对应，方便后面查询\n",
    "    forest.add(key=i, minhash=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 索引到目前为止添加的所有key，并使它们可搜索\n",
    "必备操作，不可少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 查询top-3近似最近邻居"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要查询的句子的索引号\n",
    "query_index = 8\n",
    "\n",
    "# 要查询Top-k的近似最近邻，因为有一个是原句，所以看top3时，K为4\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'辞职后的里皮没有改变原有的计划——赛后第二天他会从迪拜直接飞回意大利'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查询索引号对应的原句\n",
    "query_str = sentences[query_index]\n",
    "query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 35, 29, 38]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取top-3近似最近邻居的keys\n",
    "neighbor_keys = forest.query(minhash_list[query_index], k=K)\n",
    "neighbor_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要查询的索引8的原句:\n",
      "辞职后的里皮没有改变原有的计划——赛后第二天他会从迪拜直接飞回意大利\n",
      "\n",
      "它的近似最近邻居索引:35, 对应句子:\n",
      "国足输给叙利亚后，里皮坐不住了，直接辞职了难怪有网友说，爱护生命，远离男足\n",
      "\n",
      "查询(index=8)与邻居(index=35)的jaccard相似度:0.21875\n",
      "\n",
      "二者的真实jaccard相似度:0.19230769230769232\n",
      "********************************************************************************\n",
      "\n",
      "要查询的索引8的原句:\n",
      "辞职后的里皮没有改变原有的计划——赛后第二天他会从迪拜直接飞回意大利\n",
      "\n",
      "它的近似最近邻居索引:29, 对应句子:\n",
      "尤其是最后一句话，看好中国队的潜力，这句话真是太鼓舞人心啦\n",
      "\n",
      "查询(index=8)与邻居(index=29)的jaccard相似度:0.046875\n",
      "\n",
      "二者的真实jaccard相似度:0.038461538461538464\n",
      "********************************************************************************\n",
      "\n",
      "要查询的索引8的原句:\n",
      "辞职后的里皮没有改变原有的计划——赛后第二天他会从迪拜直接飞回意大利\n",
      "\n",
      "它的近似最近邻居索引:38, 对应句子:\n",
      "国足昨晚1-2输给叙利亚，赛后主帅里皮宣布辞职\n",
      "\n",
      "查询(index=8)与邻居(index=38)的jaccard相似度:0.2265625\n",
      "\n",
      "二者的真实jaccard相似度:0.17777777777777778\n",
      "********************************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in neighbor_keys:\n",
    "    if k == query_index:\n",
    "        continue\n",
    "    query_doc = set(documents[query_index])\n",
    "    neighbor = set(documents[k])\n",
    "    real_jaccard = len(query_doc.intersection(neighbor)) / len(query_doc.union(neighbor))\n",
    "    minhash_value = minhash_list[query_index].jaccard(minhash_list[k])\n",
    "    print(\"要查询的索引{}的原句:\\n{}\\n\".format(query_index, query_str))\n",
    "    print(\"它的近似最近邻居索引:{}, 对应句子:\\n{}\\n\".format(k, sentences[k]))\n",
    "    print(\"查询(index={})与邻居(index={})的jaccard相似度:{}\\n\".format(query_index, k, minhash_value))\n",
    "    print(\"二者的真实jaccard相似度:{}\".format(real_jaccard))\n",
    "    print('*' * 80)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对比了jieba.cut和jieba.posseg.cut，前者只分词，而后者在分词时还会标注词性，网上有人说二者分词结果会有差异，但我随机找了几个句子分词对比了下，单词结果没有发现太大区别。\n",
    "2. MinHashForest找到的jaccard相似度的值，与真实jaccard相似度确实很接近。\n",
    "3. index=8的与邻居的近似jaccard相似度:index=38 > index=35(0.2266 > 0.2188)，但真实jaccard相似度:index=38 < index=35 (0.1778 < 0.1923)，可见当近似jaccard相似度大于其他邻居的相似度时，真实jaccard相似度不一定也大于其他邻居。所以近似jaccard相似度是top1时，不一定真实相似度是第一，所以是近似最近邻查找。\n",
    "4. 找到个去除列表中空字符串的函数`filter()`，很好用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:envpy37]",
   "language": "python",
   "name": "conda-env-envpy37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
